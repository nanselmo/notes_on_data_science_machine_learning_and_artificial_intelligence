<!DOCTYPE html>
<html lang="en">

<head>
      <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="Data Science for Political and Social Phenomena">
    <meta name="author" content="Chris Albon">
    <link rel="icon" href="../favicon.ico">

    <title>Cross Validation With Parameter Tuning Using Grid Search - Machine Learning</title>

    <!-- JQuery -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script>
        window.jQuery || document.write('<script src="../theme/js/jquery.min.js"><\/script>')
    </script>

    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="../theme/css/bootstrap.css" />
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <link rel="stylesheet" type="text/css" href="../theme/css/ie10-viewport-bug-workaround.css" />
    <!-- Custom styles for this template -->
    <link rel="stylesheet" type="text/css" href="../theme/css/style.css" />
    <link rel="stylesheet" type="text/css" href="../theme/css/notebooks.css" />
    <link href='https://fonts.googleapis.com/css?family=PT+Serif:400,700|Roboto:400,500,700' rel='stylesheet' type='text/css'>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
     <link href="http://chrisalbon.com/feeds/all.rss.xml" type="application/rss+xml" rel="alternate" title="Chris Albon - Data Science, Machine Learning, and Artificial Intelligence Full RSS Feed" />         <link href="http://chrisalbon.com/feeds/machine-learning.rss.xml" type="application/rss+xml" rel="alternate" title="Chris Albon - Data Science, Machine Learning, and Artificial Intelligence Categories RSS Feed" />    

    <meta name="tags" content="Basics" />


</head>

<body>

    <div class="navbar navbar-fixed-top">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="..">Chris Albon</a>
            </div>
            <div class="navbar-collapse collapse" id="searchbar">

                <ul class="nav navbar-nav navbar-right">
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">About<span class="caret"></span></a>
                        <ul class="dropdown-menu">
                            <li><a href="../pages/about.html">About Chris</a></li>
                            <li><a href="https://github.com/chrisalbon">GitHub</a></li>
                            <li><a href="https://twitter.com/chrisalbon">Twitter</a></li>
                            <li><a href="https://www.linkedin.com/in/chrisralbon">LinkedIn</a></li>
                            <li><a href="https://pinboard.in/u:chrisalbon">Pinboard</a></li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Data Science<span class="caret"></span></a>
                        <ul class="dropdown-menu">
                            <li><a href="..#Blog">Blog</a></li>
                            <li><a href="..#Python">Python</a></li>
                            <li><a href="..#R_Stats">R Stats</a></li>
                            <li><a href="..#Regex">Regex</a></li>
                            <li><a href="..#Bash">Bash</a></li>
                            <li><a href="..#Project_Juypter">Project Juypter</a></li>
                            <li><a href="..#SQL">SQL</a></li>
                            <li><a href="..#Mathematics">Mathematics</a></li>
                            <li><a href="..#Javascript">Javascript</a></li>
                            <li><a href="..#Probability">Probability</a></li>
                            <li><a href="..#Frequentist_Statistics">Frequentist Statistics</a></li>
                            <li><a href="..#Bayesian_Statistics">Bayesian Statistics</a></li>
                            <li><a href="..#Machine_Learning">Machine Learning</a></li>
                            <li><a href="..#GitHub">GitHub</a></li>
                            <li><a href="..#Scala">Scala</a></li>
                            <li><a href="..#Spark">Spark</a></li>
                            <li><a href="..#Amazon_Web_Services">Amazon Web Services</a></li>
                            <li><a href="..#Kaggle">Kaggle</a></li>
                            <li><a href="..#Projects">Projects</a></li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Projects<span class="caret"></span></a>
                        <ul class="dropdown-menu">
                            <li><a href="http://newknowledge.io">New Knowledge</a></li>
                            <li><a href="http://partiallyderivative.com">Partially Derivative</a></li>
                            <li><a href="https://github.com/chrisalbon/notes_on_data_science_machine_learning_and_artificial_intelligence">Notes on DS, ML, and AI</a></li>
                        </ul>
                    </li>

                    <!--<li class="dropdown">
                        <a href="../feeds/blog.rss.xml">Blog RSS</a>
                    </li>-->


                </ul>

                <form class="navbar-form" action="../search.html" onsubmit="return validateForm(this.elements['q'].value);">
                    <div class="form-group" style="display:inline;">
                        <div class="input-group" style="display:table;">
                            <span class="input-group-addon" style="width:1%;"><span class="glyphicon glyphicon-search"></span></span>
                            <input class="form-control search-query" name="q" id="tipue_search_input" placeholder="e.g. scikit KNN, pandas merge" required autocomplete="off" type="text">
                        </div>
                    </div>
                </form>

            </div>
            <!--/.nav-collapse -->
        </div>
    </div>



    <!-- end of header section -->
    <div class="container">
<!-- <div class="alert alert-warning" role="alert">
    Did you find this page useful? Please do me a quick favor and <a href="#" class="alert-link">endorse me for data science on LinkedIn</a>.
</div> -->
<section id="content" class="body">
    <header>
    <h1>
      Cross Validation With Parameter Tuning Using Grid Search
    </h1>
<ol class="breadcrumb">
    <li>
        <time class="published" datetime="2016-09-06T12:00:00-07:00">
            06 September 2016
        </time>
    </li>
    <li>Machine Learning</li>
    <li>Basics</li>
</ol>
</header>
<div class='article_content'>
<p>In machine learning, two tasks are commonly done at the same time in data pipelines: cross validation and (hyper)parameter tuning. Cross validation is the process of training learners using one set of data and testing it using a different set. Parameter tuning is the process to selecting the values for a model's parameters that maximize the accuracy of the model.</p>
<p>In this tutorial we work through an example which combines cross validation and parameter tuning using scikit-learn.</p>
<p>Note: This tutorial is based on <a href="http://scikit-learn.org/stable/modules/grid_search.html#grid-search">examples given in the scikit-learn documentation</a>. I have combined a few examples in the documentation, simplified the code, and added extensive explanations/code comments.</p>
<h2>Preliminaries</h2>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.grid_search</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">svm</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
</pre></div>


<h2>Create Two Datasets</h2>
<p>In the code below, we load the <a href="http://scikit-learn.org/stable/auto_examples/datasets/plot_digits_last_image.html"><code>digits</code> dataset</a>, which contains 64 feature variables. Each feature denotes the darkness of a pixel in an 8 by 8 image of a handwritten digit. We can see these features for the first observation:</p>
<div class="codehilite"><pre><span></span><span class="c1"># Load the digit data</span>
<span class="n">digits</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_digits</span><span class="p">()</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="c1"># View the features of the first observation</span>
<span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]</span>
</pre></div>


<div class="codehilite"><pre><span></span>array([[  0.,   0.,   5.,  13.,   9.,   1.,   0.,   0.,   0.,   0.,  13.,
         15.,  10.,  15.,   5.,   0.,   0.,   3.,  15.,   2.,   0.,  11.,
          8.,   0.,   0.,   4.,  12.,   0.,   0.,   8.,   8.,   0.,   0.,
          5.,   8.,   0.,   0.,   9.,   8.,   0.,   0.,   4.,  11.,   0.,
          1.,  12.,   7.,   0.,   0.,   2.,  14.,   5.,  10.,  12.,   0.,
          0.,   0.,   0.,   6.,  13.,  10.,   0.,   0.,   0.]])
</pre></div>


<p>The target data is a vector containing the image's true digit. For example, the first observation is a handwritten digit for '0'.</p>
<div class="codehilite"><pre><span></span><span class="c1"># View the target of the first observation</span>
<span class="n">digits</span><span class="o">.</span><span class="n">target</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]</span>
</pre></div>


<div class="codehilite"><pre><span></span>array([0])
</pre></div>


<p>To demonstrate cross validation and parameter tuning, first we are going to divide the digit data into two datasets called <code>data1</code> and <code>data2</code>. <code>data1</code> contains the first 1000 rows of the digits data, while <code>data2</code> contains the remaining ~800 rows. Note that this split is <em>separate</em> to the cross validation we will conduct and is done purely to demonstrate something at the end of the tutorial. In other words, don't worry about <code>data2</code> for now, we will come back to it.</p>
<div class="codehilite"><pre><span></span><span class="c1"># Create dataset 1</span>
<span class="n">data1_features</span> <span class="o">=</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">[:</span><span class="mi">1000</span><span class="p">]</span>
<span class="n">data1_target</span> <span class="o">=</span> <span class="n">digits</span><span class="o">.</span><span class="n">target</span><span class="p">[:</span><span class="mi">1000</span><span class="p">]</span>

<span class="c1"># Create dataset 2</span>
<span class="n">data2_features</span> <span class="o">=</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">1000</span><span class="p">:]</span>
<span class="n">data2_target</span> <span class="o">=</span> <span class="n">digits</span><span class="o">.</span><span class="n">target</span><span class="p">[</span><span class="mi">1000</span><span class="p">:]</span>
</pre></div>


<h2>Create Parameter Candidates</h2>
<p>Before looking for which combination of parameter values produces the most accurate model, we must specify the different candidate values we want to try. In the code below we have a number of candidate parameter values, including four different values for <code>C</code> (<code>1, 10, 100, 1000</code>), two values for <code>gamma</code> (<code>0.001, 0.0001</code>), and two kernels (<code>linear, rbf</code>). The grid search will try all combinations of parameter values and select the set of parameters which provides the most accurate model.</p>
<div class="codehilite"><pre><span></span><span class="n">parameter_candidates</span> <span class="o">=</span> <span class="p">[</span>
  <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">],</span> <span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">]},</span>
  <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">],</span> <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">],</span> <span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;rbf&#39;</span><span class="p">]},</span>
<span class="p">]</span>
</pre></div>


<h2>Conduct Grid Search To Find Parameters Producing Highest Score</h2>
<p>Now we are ready to conduct the grid search using scikit-learn's <code>GridSearchCV</code> which stands for grid search cross validation. By default, the <code>GridSearchCV</code>'s cross validation uses 3-fold <code>KFold</code> or <code>StratifiedKFold</code> depending on the situation.</p>
<div class="codehilite"><pre><span></span><span class="c1"># Create a classifier object with the classifier and parameter candidates</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(),</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">parameter_candidates</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Train the classifier on data1&#39;s feature and target data</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data1_features</span><span class="p">,</span> <span class="n">data1_target</span><span class="p">)</span>   
</pre></div>


<div class="codehilite"><pre><span></span>GridSearchCV(cv=None, error_score=&#39;raise&#39;,
       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=&#39;auto&#39;, kernel=&#39;rbf&#39;,
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False),
       fit_params={}, iid=True, n_jobs=-1,
       param_grid=[{&#39;kernel&#39;: [&#39;linear&#39;], &#39;C&#39;: [1, 10, 100, 1000]}, {&#39;kernel&#39;: [&#39;rbf&#39;], &#39;gamma&#39;: [0.001, 0.0001], &#39;C&#39;: [1, 10, 100, 1000]}],
       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, scoring=None, verbose=0)
</pre></div>


<p>Success! We have our results! First, let's look at the accuracy score when we apply the model to the <code>data1</code>'s test data.</p>
<div class="codehilite"><pre><span></span><span class="c1"># View the accuracy score</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Best score for data1:&#39;</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>Best score for data1: 0.942
</pre></div>


<p>Which parameters are the best? We can tell scikit-learn to display them:</p>
<div class="codehilite"><pre><span></span><span class="c1"># View the best parameters for the model found using grid search</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Best C:&#39;</span><span class="p">,</span><span class="n">clf</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">C</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Best Kernel:&#39;</span><span class="p">,</span><span class="n">clf</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">kernel</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Best Gamma:&#39;</span><span class="p">,</span><span class="n">clf</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">gamma</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>Best C: 10
Best Kernel: rbf
Best Gamma: 0.001
</pre></div>


<p>This tells us that the most accurate model uses <code>C=10</code>, the <code>rbf</code> kernel, and <code>gamma=0.001</code>.</p>
<h2>Sanity Check Using Second Dataset</h2>
<p>Remember the second dataset we created? Now we will use it to prove that those parameters are actually used by the model. First, we apply the classifier we just trained to the second dataset. Then we will train a <em>new</em> support vector classifier from scratch using the parameters found using the grid search. We should get the same results for both models.</p>
<div class="codehilite"><pre><span></span><span class="c1"># Apply the classifier trained using data1 to data2, and view the accuracy score</span>
<span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">data2_features</span><span class="p">,</span> <span class="n">data2_target</span><span class="p">)</span>  
</pre></div>


<div class="codehilite"><pre><span></span>0.96988707653701378
</pre></div>


<div class="codehilite"><pre><span></span><span class="c1"># Train a new classifier using the best parameters found by the grid search</span>
<span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data1_features</span><span class="p">,</span> <span class="n">data1_target</span><span class="p">)</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">data2_features</span><span class="p">,</span> <span class="n">data2_target</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>0.96988707653701378
</pre></div>


<p>Success!</p>
</div>
    <aside>
    <div class="bug-reporting__panel">
        <h3>Find an error or bug? Have a suggestion?</h3>
        <p>Everything on this site is avaliable on GitHub. Head on over and <a href='https://github.com/chrisalbon/notes_on_data_science_machine_learning_and_artificial_intelligence/issues/new'>submit an issue.</a> You can also message me directly on <a href='https://twitter.com/chrisalbon'>Twitter</a>.</p>
    </div>
    </aside>
</section>

    </div>
    <!-- start of footer section -->
    <footer class="footer">
        <div class="container">
            <p class="text-muted">
                <center>This project contains 432 pages and is available on <a href="https://github.com/chrisalbon/notes_on_data_science_machine_learning_and_artificial_intelligence">GitHub</a>.
                <br/>
                Copyright &copy; Chris Albon,
                    <time datetime="2016">2016</time>.
                </center>
            </p>
        </div>
    </footer>

    <!-- This jQuery line finds any span that contains code highlighting classes and then selects the parent <pre> tag and adds a border. This is done as a workaround to visually distinguish the code inputs and outputs -->
    <script>
        $( ".hll, .n, .c, .err, .k, .o, .cm, .cp, .c1, .cs, .gd, .ge, .gr, .gh, .gi, .go, .gp, .gs, .gu, .gt, .kc, .kd, .kn, .kp, .kr, .kt, .m, .s, .na, .nb, .nc, .no, .nd, .ni, .ne, .nf, .nl, .nn, .nt, .nv, .ow, .w, .mf, .mh, .mi, .mo, .sb, .sc, .sd, .s2, .se, .sh, .si, .sx, .sr, .s1, .ss, .bp, .vc, .vg, .vi, .il" ).parent( "pre" ).css( "border", "1px solid #DEDEDE" );
    </script>

    <!-- Load Google Analytics -->
    <script>
        (function(i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function() {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-66582-32', 'auto');
        ga('send', 'pageview');
    </script>
    <!-- End of Google Analytics -->

    <!-- Bootstrap core JavaScript
      ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../theme/js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="../theme/js/ie10-viewport-bug-workaround.js"></script>
</body>

</html>